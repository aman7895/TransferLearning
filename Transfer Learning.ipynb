{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import json\n",
    "import py_crepe\n",
    "import datetime\n",
    "import numpy as np\n",
    "import data_helpersTL\n",
    "import dataTL\n",
    "import string\n",
    "import pandas as pd\n",
    "np.random.seed(0123)  # for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "\n",
    "subset = None\n",
    "\n",
    "#Whether to save model parameters\n",
    "save = False\n",
    "model_name_path = 'params/crepe_model.json'\n",
    "model_weights_path = 'params/crepe_model_weights.h5'\n",
    "\n",
    "#Maximum length. Longer gets chopped. Shorter gets padded.\n",
    "maxlen = 1014\n",
    "\n",
    "#Model params\n",
    "#Filters for conv layers\n",
    "nb_filter = 128 #initially 256\n",
    "#Number of units in the dense layer\n",
    "dense_outputs = 512 #Initially 1024\n",
    "#Conv layer kernel size\n",
    "filter_kernels = [7, 7, 3, 3, 3, 3]\n",
    "#Number of units in the final output layer. Number of classes.\n",
    "\n",
    "#Compile/fit params\n",
    "batch_size = 32\n",
    "nb_epoch = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Execution completed\n",
      "Read completed\n",
      "Number of rows: 44\n",
      "author_id       int64\n",
      "doc_content    object\n",
      "dtype: object\n",
      "Data Frame created: Shape: (13608, 2)\n",
      "Author:   114  Size: 11925\n",
      "Author:   124  Size:   415\n",
      "Author:  1228  Size:   506\n",
      "Author:  1492  Size:   762\n",
      "Min: 415\n",
      "Max: 11925\n",
      "Authors [114, 124, 1228, 1492].\n",
      "Found 1660 texts.\n",
      "Found 1660 labels.\n",
      "Creating vocab...\n",
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "#Expect x to be a list of sentences. Y to be a one-hot encoding of the\n",
    "#categories.\n",
    "\n",
    "### 515-1122-122 and 1573 with remove 6 layers\n",
    "#authorlist=[121, 479 , 649 ]\n",
    "#doc_id = 14706\n",
    "\n",
    "authorlist=[ 114, 1492, 124, 1228]\n",
    "doc_id = [206, 205]\n",
    "cat_output = len(authorlist) #binary in the last layer\n",
    "\n",
    "# def main(authorlist, doc_id):\n",
    "    \n",
    "    \n",
    "((trainX, trainY), (valX, valY)) = data_helpersTL.load_ag_data(authors = authorlist, docID = doc_id)\n",
    "\n",
    "print('Creating vocab...')\n",
    "vocab, reverse_vocab, vocab_size, check = data_helpersTL.create_vocab_set()\n",
    "\n",
    "\n",
    "#trainX = data_helpers.encode_data(trainX, maxlen, vocab, vocab_size, check)\n",
    "#test_data = data_helpers.encode_data(valX, maxlen, vocab, vocab_size, check)\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "classes = len(authorlist)\n",
    "import cPickle as pickle\n",
    "with open('sgd.pickle', 'rb') as handle:\n",
    "    sgd = pickle.load(handle)\n",
    "\n",
    "(model) = py_crepe.build_feature_model(classes, filter_kernels, dense_outputs, maxlen,\n",
    "                                       vocab_size, nb_filter, sgd, model_weights_path)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model...\n",
      "Epoch: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4145152 into shape (32,1008,128)\nApply node that caused the error: Reshape{3}(InplaceDimShuffle{0,2,3,1}.0, MakeVector{dtype='int64'}.0)\nToposort index: 10\nInputs types: [TensorType(float32, 4D), TensorType(int64, vector)]\nInputs shapes: [(32, 1012, 1, 128), (3,)]\nInputs strides: [(518144, 4, 518144, 4048), (8,)]\nInputs values: ['not shown', array([  32, 1008,  128])]\nOutputs clients: [[InplaceDimShuffle{0,2,1,x}(Reshape{3}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/home/aman/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-6328ba9f5dac>\", line 33, in <module>\n    vocab_size, nb_filter, sgd, model_weights_path)\n  File \"py_crepe.py\", line 80, in build_feature_model\n    name = 'conv1', trainable = False))\n  File \"/home/aman/anaconda2/lib/python2.7/site-packages/keras/models.py\", line 430, in add\n    layer(x)\n  File \"/home/aman/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py\", line 578, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/aman/anaconda2/lib/python2.7/site-packages/keras/layers/convolutional.py\", line 156, in call\n    dilation_rate=self.dilation_rate[0])\n  File \"/home/aman/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py\", line 1726, in conv1d\n    output = squeeze(output, 2)\n  File \"/home/aman/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py\", line 927, in squeeze\n    y = T.reshape(x, tuple(shape))\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e1826c60c25e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mfeature_trainX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_trainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aman/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aman/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1571\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1573\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/aman/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1201\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aman/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aman/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aman/anaconda2/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aman/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 4145152 into shape (32,1008,128)\nApply node that caused the error: Reshape{3}(InplaceDimShuffle{0,2,3,1}.0, MakeVector{dtype='int64'}.0)\nToposort index: 10\nInputs types: [TensorType(float32, 4D), TensorType(int64, vector)]\nInputs shapes: [(32, 1012, 1, 128), (3,)]\nInputs strides: [(518144, 4, 518144, 4048), (8,)]\nInputs values: ['not shown', array([  32, 1008,  128])]\nOutputs clients: [[InplaceDimShuffle{0,2,1,x}(Reshape{3}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/home/aman/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-6328ba9f5dac>\", line 33, in <module>\n    vocab_size, nb_filter, sgd, model_weights_path)\n  File \"py_crepe.py\", line 80, in build_feature_model\n    name = 'conv1', trainable = False))\n  File \"/home/aman/anaconda2/lib/python2.7/site-packages/keras/models.py\", line 430, in add\n    layer(x)\n  File \"/home/aman/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py\", line 578, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/aman/anaconda2/lib/python2.7/site-packages/keras/layers/convolutional.py\", line 156, in call\n    dilation_rate=self.dilation_rate[0])\n  File \"/home/aman/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py\", line 1726, in conv1d\n    output = squeeze(output, 2)\n  File \"/home/aman/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py\", line 927, in squeeze\n    y = T.reshape(x, tuple(shape))\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "print('Fit model...')\n",
    "initial = datetime.datetime.now()\n",
    "for e in xrange(nb_epoch):\n",
    "    xi, yi = data_helpersTL.shuffle_matrix(trainX, trainY)\n",
    "    xi_test, yi_test = data_helpersTL.shuffle_matrix(valX, valY)\n",
    "    if subset:\n",
    "        batches = data_helpersTL.mini_batch_generator(xi[:subset], yi[:subset],\n",
    "                                                    vocab, vocab_size, check,\n",
    "                                                    maxlen,\n",
    "                                                    batch_size=batch_size)\n",
    "    else:\n",
    "        batches = data_helpersTL.mini_batch_generator(xi, yi, vocab, vocab_size,\n",
    "                                                    check, maxlen,\n",
    "                                                    batch_size=batch_size)\n",
    "\n",
    "    test_batches = data_helpersTL.mini_batch_generator(xi_test, yi_test, vocab,\n",
    "                                                     vocab_size, check, maxlen,\n",
    "                                                     batch_size=batch_size)\n",
    "    \n",
    "    \n",
    "    accuracy = 0.0\n",
    "    loss = 0.0\n",
    "    step = 1\n",
    "    start = datetime.datetime.now()\n",
    "    print('Epoch: {}'.format(e))\n",
    "    for x_train, y_train in batches:\n",
    "        feature_trainX = model.predict(x_train)\n",
    "        clf.partial_fit(feature_trainX)\n",
    "    \n",
    "    test_accuracy = 0.0\n",
    "    test_loss = 0.0\n",
    "    test_step = 1\n",
    "    \n",
    "    \n",
    "    for x_test_batch, y_test_batch in test_batches:\n",
    "        feature_testX = model.predict(x_test_batch)\n",
    "        test_accuracy += clf.predict(feature_testX)\n",
    "        test_accuracy_avg = test_accuracy / test_step\n",
    "        test_step += 1\n",
    "        \n",
    "    print('Epoch {}. Loss: {}. Accuracy: {}\\n'.format(e, test_accuracy_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del trainX, trainY, valX, valY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
